# -*- coding: utf-8 -*-
"""project1_rrp_551.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A7Fc-x4Xels24O4zEPArytgAt39NEXA2
"""

# 1. Install the Kaggle library

! pip install kaggle
# 2. Make a directory named “.kaggle”

! mkdir ~/.kaggle
# 3. Copy the “kaggle.json” into this new directory

! cp kaggle.json ~/.kaggle/
# 4. Allocate the required permission for this file.

! chmod 600 ~/.kaggle/kaggle.json

!wget kaggle competitions download -c restaurant-revenue-prediction

! pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

! kaggle competitions download -c '/competitions/restaurant-revenue-prediction/data'

import pandas as pd
import numpy as np
import tensorflow as tf
import sys
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error as mse
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import LabelEncoder

df=pd.read_csv("train.csv")
# print(df.head())
df1=pd.read_csv("test.csv")
# print(df1.head())
df.head()

import seaborn as sns
sns.distplot(df.revenue)

from sklearn.preprocessing import PowerTransformer
p=PowerTransformer(method= 'box-cox')
df['revenue']=p.fit_transform(df[['revenue']])
sns.distplot(df.revenue)

# df['Open_Date'] = df['Open Date']

# df.iloc[:,1].unique()

# df.Open_Date = pd.to_datetime(df.Open_Date,dayfirst = False)

# df[['year']] = pd.DataFrame(df.Open_Date.dt.year)
# df[['day']] = pd.DataFrame(df.Open_Date.dt.day)
# df[['month']] = pd.DataFrame(df.Open_Date.dt.month)

df

df.info()

cols = df.select_dtypes(include=['object'])
from sklearn.preprocessing import LabelEncoder
l = LabelEncoder()
for i in cols:
  df[i] = l.fit_transform(df[i])

import seaborn as sns
import matplotlib.pyplot as plt
corr = df.corr()
f, ax = plt.subplots(figsize=(28, 24))
mask = np.triu(np.ones_like(corr, dtype=bool))
cmap = sns.diverging_palette(230, 20, as_cmap=True)
sns.heatmap(corr, annot=True, mask = mask, cmap=cmap)

df = df.drop('City',axis=1)

df = df.drop('Id',axis=1)

df = df.drop('Open Date',axis=1)

df = df.drop('City Group',axis=1)

df = df.drop('P22',axis=1)

# df = df.drop('P5',axis=1)

target = df['revenue']
features = df.drop('revenue',axis=1)



df.head()

sns.heatmap(df.isnull(), cbar=False)

X_train_full, X_test, y_train_full, y_test = train_test_split(
    features, target, random_state=42)
X_train, X_valid, y_train, y_valid = train_test_split(
    X_train_full, y_train_full, random_state=42)

print(type(features))
print(type(target))

features = features.to_numpy()
target = target.to_numpy()



from keras.models import Sequential
model = Sequential()
from keras.layers import Dense
model.add(Dense(41,input_dim=37,activation='relu'))
model.add(Dense(41,activation='relu'))
model.add(Dense(1))

model.compile(loss='mse',optimizer='Adam',metrics=['mean_squared_error'])

model.fit(X_train,y_train,epochs=100,batch_size=10)

X_train

y_train

# model.fit(features,target,epochs=50)
df1.info()

X_test = df1
X_test

_, accuracy = model.evaluate(X_valid,y_valid)

y_predict = model.predict(X_test)



from sklearn import linear_model
le = linear_model.LinearRegression()

le.fit(X_train,y_train)

le.score(X_train,y_train)



y_valid_predict = model.predict(X_valid)

